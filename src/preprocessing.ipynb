{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1648597741011,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "qgfIb_44n_iY",
    "outputId": "6ef20146-e3e1-4e4f-81bf-5c437b872819"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não Se Esquecerá</td>\n",
       "      <td>Forrozão Tropykália</td>\n",
       "      <td>0</td>\n",
       "      <td>Sei que poderá levar um tempo Sei que poderá d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title               artist  year  \\\n",
       "0  Não Se Esquecerá  Forrozão Tropykália     0   \n",
       "\n",
       "                                               lyric  \n",
       "0  Sei que poderá levar um tempo Sei que poderá d...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/lyrics.csv', sep=';', encoding=\"utf-8\")\n",
    "\n",
    "# Remoção de colunas que não serão utilizadas na análise\n",
    "df.drop(columns=['id', 'composer', 'album'], inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos títulos das músicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'De Coração Virado (Morena)'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_title = df.loc[87, 'title']\n",
    "normal_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "pLJkEckLGFs5"
   },
   "outputs": [],
   "source": [
    "# igualando todos os títulos para minúsculo\n",
    "df['title'] = df['title'].str.lower()\n",
    "\n",
    "# limpeza dos títulos com símbolos\n",
    "df['title'].replace(\"\\((.*?)\\)\", '', regex=True, inplace=True)\n",
    "\n",
    "# removendo espaços nas extremidades\n",
    "df['title'] = df['title'].str.strip()\n",
    "\n",
    "#capitalizando título\n",
    "df['title'] = df['title'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'De Coração Virado'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_title = df.loc[87, 'title']\n",
    "processed_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OjwT4QIP6DD"
   },
   "source": [
    "### Remoção das músicas sem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648597745452,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "2kAqfTutOJ3y",
    "outputId": "48d2a812-dc73-43a4-ca84-7022fe5d3a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de músicas com data: 11046\n"
     ]
    }
   ],
   "source": [
    "df = df[df['year'] > 0]\n",
    "\n",
    "print(f'Quantidade de músicas com data: {df.title.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxMvcbz1IepS"
   },
   "source": [
    "### Remoção dos registros sem letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11046 entries, 2359 to 13404\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   11046 non-null  object\n",
      " 1   artist  11046 non-null  object\n",
      " 2   year    11046 non-null  int64 \n",
      " 3   lyric   10995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 431.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1648598631168,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "tD2STUlLHriL",
    "outputId": "33677e2c-dcbc-4fc9-80ba-53e1eb38ccef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros com letras: 10995\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['lyric'].isnull()]\n",
    "print(f'Quantidade de registros com letras: {df.lyric.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10995 entries, 2359 to 13404\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   10995 non-null  object\n",
      " 1   artist  10995 non-null  object\n",
      " 2   year    10995 non-null  int64 \n",
      " 3   lyric   10995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 429.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento das letras musicais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./data/clean_lyrics.csv', index=False)\n",
    "df = pd.read_csv('./data/clean_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remoção de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dataset de sujeiras encontradas em algumas letras\n",
    "noise = pd.read_csv('./data/stop_words.txt')\n",
    "noise = noise['stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "lyric_noise = set(noise.to_list())\n",
    "stop_words = STOP_WORDS.union(lyric_noise)\n",
    "stop_words = [word for word in stop_words]\n",
    "\n",
    "#palavras como não e nem possuem muito significado para o texto. Portanto foram removidas das SW\n",
    "stop_words.remove('não')\n",
    "stop_words.remove('nem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_lyrics(text):\n",
    "  txt = ''\n",
    "  #caracteres em minusculo   \n",
    "  txt = text.lower()\n",
    "  #coletando apenas letras\n",
    "  words = re.findall('[a-zéóáêâãõç]+', txt)\n",
    "  txt = (' ').join(words)\n",
    "  #remove stop words\n",
    "  doc = nlp(txt)\n",
    "  txt = ' '.join( token.text \n",
    "                  for token in doc \n",
    "                  if not token.is_digit\n",
    "                  and token.text not in stop_words\n",
    "                )\n",
    "  \n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes: Morena sereia Que à beira-mar não passeia Que senta na praia e deixa a praia cheia De lindos castelos de areia Cuidado criança Que qualquer dia um tufão Derruba estes teus castelos de esperança E enche de areia o teu coração Se algum dia tu souberes Que o teu nome eu escrevi Entre mais de dez nomes de mulheres Terás certeza que te amei mas te esqueci\n",
      "depois: morena sereia beira mar não passeia senta praia deixa praia cheia lindos castelos areia cuidado criança dia tufão derruba castelos esperança enche areia coração algum dia souberes nome escrevi nomes mulheres terás amei esqueci\n"
     ]
    }
   ],
   "source": [
    "## Testando preprocessmaneto\n",
    "normal_lyric = df.loc[1, 'lyric']\n",
    "processed_lyric = clean_lyrics(normal_lyric)\n",
    "\n",
    "print(f'antes: {normal_lyric}')\n",
    "print(f'depois: {processed_lyric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo ruídos das letras\n",
    "df['clean_lyric'] = df['lyric'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bertaglia, Thales Felipe Costa, and Maria das Graças Volpe Nunes. \n",
    "“Exploring Word Embeddings for Unsupervised Textual User-Generated Content Normalization.” \n",
    "Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT). 2016.\n",
    "\"\"\"\n",
    "from enelvo.normaliser import Normaliser\n",
    "norm = Normaliser()\n",
    "\n",
    "def clean_lyrics_2(lyric):\n",
    "    normalized = ' '.join(norm.normalise(word) for word in lyric.split())\n",
    "    doc = nlp(normalized)\n",
    "    text = (' ').join(\n",
    "                        token.lemma_\n",
    "                        if token.pos_ == 'VERB'\n",
    "                        and token.text not in stop_words\n",
    "                        else token.text\n",
    "                        for token in doc\n",
    "                    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes: não discuto teimoso não perder precioso viver joão teimoso nome dorme pé rede bebida fome comida sede foge meninas boas prefere coroas começa não pára cara cismo cara\n"
     ]
    }
   ],
   "source": [
    "processed_lyric = df.loc[0, 'clean_lyric']\n",
    "print(f'antes: {processed_lyric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_lyric'] = df['clean_lyric'].apply(clean_lyrics_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depois: não discuto teimoso não perder precioso viver joão teimoso nome dormir pé rede bebido fome comido sede foge meninas boas preferir coroas comedir não parir caro cismo caro\n"
     ]
    }
   ],
   "source": [
    "print(f'depois: {clean_lyrics_2(processed_lyric)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para remover palavras que contêm repetições sequenciais\n",
    "def remove_words_with_reps(text):\n",
    "  words = text.split()\n",
    "  for i, word in enumerate(words):\n",
    "      reps = 0\n",
    "      for j, character in enumerate(word):\n",
    "        if j > 0 and character == word[j-1]:\n",
    "            reps+=1\n",
    "      if reps > 1:\n",
    "        words.pop(i)\n",
    "      \n",
    "  return (' ').join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes: diferença mulher home esperar home cabelo peitar queixo cabeludo mulher não so dia manhã adão comer maçã eva comeu ficar adão eva adão dar mancada eva dar mulher perna braço coxa nariz boca muita inteligência bicho homem jeito reparar direito pouquinho diferença breque achar diferença sapato não homem\n",
      "depois: diferença mulher home esperar home cabelo peitar queixo cabeludo mulher não so dia manhã adão comer maçã eva comeu ficar adão eva adão dar mancada eva dar mulher perna braço coxa nariz boca muita inteligência bicho homem jeito reparar direito pouquinho diferença breque achar diferença sapato não homem\n"
     ]
    }
   ],
   "source": [
    "#Testando removedor de sequenciais\n",
    "lyric = df.loc[245, 'clean_lyric']\n",
    "processed_lyric = remove_words_with_reps(lyric)\n",
    "\n",
    "print(f'antes: {lyric}')\n",
    "print(f'depois: {processed_lyric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_lyric'] = df['clean_lyric'].apply(remove_words_with_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criando decadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para criar decadas\n",
    "decade = lambda year: int(((((year - (year % 10)) / 10) % 10) * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerando decadas\n",
    "df['decade'] = df['year'].apply(decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gerando colunas de palavras únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para retornar palavras unicas\n",
    "unique = lambda text: set(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unique_words'] = df['clean_lyric'].apply(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passando letras para listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para retornar palavras em formato de lista\n",
    "to_words = lambda text: text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando letras em lista de palavras\n",
    "df['words'] = df['clean_lyric'].apply(to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armazenando\n",
    "df.to_csv('./data/clean_lyrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQR2xgyW7WOrCQnX18yeFp",
   "collapsed_sections": [],
   "name": "higienizacao_df.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "22b04671355daadbbed3e848c51a8cb4ceea07cad10492c09cb5f8a9e64564b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
