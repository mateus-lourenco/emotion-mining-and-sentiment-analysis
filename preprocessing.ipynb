{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLhaOlYInh7x"
   },
   "source": [
    "# **Extração de emoções e Análise de Sentimentos em Letras de músicas do Forró**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8QnKiYgInZMj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1648597741011,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "qgfIb_44n_iY",
    "outputId": "6ef20146-e3e1-4e4f-81bf-5c437b872819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13405, 7)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./lyrics.csv', sep=';', encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQaZmBRkylNe"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJThpaqxyu-q"
   },
   "source": [
    "1. Remoção dos títulos das músicas que contenham os caracteres '()' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "pLJkEckLGFs5"
   },
   "outputs": [],
   "source": [
    "df['title'].replace(\"\\((.*?)\\)\", '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl_pJYjmBhS9"
   },
   "source": [
    "\n",
    "\n",
    "2. Remoção das músicas duplicadas a partir do título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4103,
     "status": "ok",
     "timestamp": 1648597745100,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "wewiz2rJp7mn",
    "outputId": "951f22c1-e4c0-4627-cd12-eb1d91788d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de duplicatas: 3484\n"
     ]
    }
   ],
   "source": [
    "df['title'] = df['title'].str.lower()\n",
    "df['title'] = df['title'].str.strip()\n",
    "\n",
    "titles = [i for i in df['title']]\n",
    "\n",
    "duplicates = [i for i in titles if titles.count(i) > 1]\n",
    "print(f'Quantidade de duplicatas: {len(duplicates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1648597745450,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "xMzdt0tcyfH5",
    "outputId": "5704f1be-10da-45b5-f915-a072910ad553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de músicas após remoção das duplicatas: 9921\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['title'].isin(duplicates)]\n",
    "print(f'Quantidade de músicas após remoção das duplicatas: {df.id.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OjwT4QIP6DD"
   },
   "source": [
    "3. Remoção das músicas sem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648597745452,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "2kAqfTutOJ3y",
    "outputId": "48d2a812-dc73-43a4-ca84-7022fe5d3a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de músicas com data: 8176\n"
     ]
    }
   ],
   "source": [
    "df = df[df['year'] > 0]\n",
    "\n",
    "print(f'Quantidade de músicas com data: {df.id.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxMvcbz1IepS"
   },
   "source": [
    "4. Remoção dos registros sem letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1648598631168,
     "user": {
      "displayName": "Mateus Cunha Lourenço",
      "userId": "17013560479942289923"
     },
     "user_tz": 180
    },
    "id": "tD2STUlLHriL",
    "outputId": "33677e2c-dcbc-4fc9-80ba-53e1eb38ccef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros com letras: 8133\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['lyric'].isnull()]\n",
    "print(f'Quantidade de registros com letras: {df.lyric.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lexicon source is (C) 2016 National Research Council Canada (NRC) \n",
    "and library is for research purposes only.  \n",
    "Source: http://sentiment.nrc.ca/lexicons-for-research/\n",
    "\"\"\"\n",
    "lexicon = pd.read_csv('./pt-nrc-lexicon.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>composer</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>lyric</th>\n",
       "      <th>clean_lyric</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>13398</td>\n",
       "      <td>probleminha</td>\n",
       "      <td>DJ Ivis</td>\n",
       "      <td>DJ Ivis / Junior Gomes.</td>\n",
       "      <td>Eu Ouvi Brasil</td>\n",
       "      <td>2021</td>\n",
       "      <td>Sabe porque não saio da tua mente? É que na ca...</td>\n",
       "      <td>Sabe porque não saio da tua mente? É que na ca...</td>\n",
       "      <td>{tu, largar, Que, logo, Assume, ele, quer, Tu,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>13399</td>\n",
       "      <td>me chama vai</td>\n",
       "      <td>DJ Ivis</td>\n",
       "      <td>Val Lima.</td>\n",
       "      <td>Eu Ouvi Brasil</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tá faltando o quê? Pra tu ligar e eu atender A...</td>\n",
       "      <td>Tá faltando o quê? Pra tu ligar e eu atender A...</td>\n",
       "      <td>{tu, Cuida, ligar, hoje, amor, já, fazer, vai,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>13400</td>\n",
       "      <td>bundão</td>\n",
       "      <td>DJ Ivis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eu Ouvi Brasil</td>\n",
       "      <td>2021</td>\n",
       "      <td>Avisa que ela voltou Tá online na parada Ficou...</td>\n",
       "      <td>Avisa que ela voltou Tá online na parada Ficou...</td>\n",
       "      <td>{mandando, hoje, Que, fogo, ex, parada, Danny,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>13403</td>\n",
       "      <td>seu love sou eu</td>\n",
       "      <td>DJ Ivis</td>\n",
       "      <td>Sammy Coelho / Valter Danadão.</td>\n",
       "      <td>Eu Ouvi Brasil</td>\n",
       "      <td>2021</td>\n",
       "      <td>Vai começar de novo Vai quebrar a cara Depois ...</td>\n",
       "      <td>Vai começar de novo Vai quebrar a cara Depois ...</td>\n",
       "      <td>{tu, Você, nunca, iludir, Que, cena, Achando, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>13404</td>\n",
       "      <td>amor é o que eu sinto</td>\n",
       "      <td>O Melhor do Forró Gospel</td>\n",
       "      <td>Sebhasttião Alves.</td>\n",
       "      <td>Forró Gospel Mais Tocadas</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teu olhar é tão belo Teu sorriso é tão lindo M...</td>\n",
       "      <td>Teu olhar é tão belo Teu sorriso é tão lindo M...</td>\n",
       "      <td>{Teu, sorriso, lindo, por, não, és, o, tão, Am...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  title                    artist  \\\n",
       "8128  13398            probleminha                   DJ Ivis   \n",
       "8129  13399           me chama vai                   DJ Ivis   \n",
       "8130  13400                 bundão                   DJ Ivis   \n",
       "8131  13403        seu love sou eu                   DJ Ivis   \n",
       "8132  13404  amor é o que eu sinto  O Melhor do Forró Gospel   \n",
       "\n",
       "                            composer                      album  year  \\\n",
       "8128         DJ Ivis / Junior Gomes.             Eu Ouvi Brasil  2021   \n",
       "8129                       Val Lima.             Eu Ouvi Brasil  2021   \n",
       "8130                             NaN             Eu Ouvi Brasil  2021   \n",
       "8131  Sammy Coelho / Valter Danadão.             Eu Ouvi Brasil  2021   \n",
       "8132              Sebhasttião Alves.  Forró Gospel Mais Tocadas  2022   \n",
       "\n",
       "                                                  lyric  \\\n",
       "8128  Sabe porque não saio da tua mente? É que na ca...   \n",
       "8129  Tá faltando o quê? Pra tu ligar e eu atender A...   \n",
       "8130  Avisa que ela voltou Tá online na parada Ficou...   \n",
       "8131  Vai começar de novo Vai quebrar a cara Depois ...   \n",
       "8132  Teu olhar é tão belo Teu sorriso é tão lindo M...   \n",
       "\n",
       "                                            clean_lyric  \\\n",
       "8128  Sabe porque não saio da tua mente? É que na ca...   \n",
       "8129  Tá faltando o quê? Pra tu ligar e eu atender A...   \n",
       "8130  Avisa que ela voltou Tá online na parada Ficou...   \n",
       "8131  Vai começar de novo Vai quebrar a cara Depois ...   \n",
       "8132  Teu olhar é tão belo Teu sorriso é tão lindo M...   \n",
       "\n",
       "                                           unique_words  decade  \n",
       "8128  {tu, largar, Que, logo, Assume, ele, quer, Tu,...      20  \n",
       "8129  {tu, Cuida, ligar, hoje, amor, já, fazer, vai,...      20  \n",
       "8130  {mandando, hoje, Que, fogo, ex, parada, Danny,...      20  \n",
       "8131  {tu, Você, nunca, iludir, Que, cena, Achando, ...      20  \n",
       "8132  {Teu, sorriso, lindo, por, não, és, o, tão, Am...      20  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gerando decadas\n",
    "df['decade'] = df['year'].apply(decade)\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo ruídos das letras\n",
    "df['clean_lyric'] = df['lyric'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo letras nulas\n",
    "df['clean_lyric'] = df[~df['clean_lyric'].isnull()]['clean_lyric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armazenando\n",
    "df.to_csv('clean_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para criar decadas\n",
    "decade = lambda year: int(((((year - (year % 10)) / 10) % 10) * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>composer</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>lyric</th>\n",
       "      <th>clean_lyric</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2360</td>\n",
       "      <td>joão teimoso</td>\n",
       "      <td>Marília Batista</td>\n",
       "      <td>Noel Rosa / Marilia Batista.</td>\n",
       "      <td>Poeta da Vila</td>\n",
       "      <td>1953</td>\n",
       "      <td>Tenho mais o que fazer Não discuto com teimoso...</td>\n",
       "      <td>discuto teimoso perder precioso viver joão tei...</td>\n",
       "      <td>{'Este', 'Não', 'viver', 'fome', 'em', 'nome',...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2361</td>\n",
       "      <td>morena sereia</td>\n",
       "      <td>Marília Batista</td>\n",
       "      <td>José Maria De Abreu 1936 / Noel Rosa.</td>\n",
       "      <td>Poeta da Vila</td>\n",
       "      <td>1953</td>\n",
       "      <td>Morena sereia Que à beira-mar não passeia Que ...</td>\n",
       "      <td>morena sereia beiramar passeia senta praia dei...</td>\n",
       "      <td>{'dia', 'tu', 'esperança', 'Que', 'castelos', ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2362</td>\n",
       "      <td>parabéns, guanabara</td>\n",
       "      <td>Jackson do Pandeiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jackson do Pandeiro - 1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>Rio, querida Guanabara Eu sou gente também Ace...</td>\n",
       "      <td>rio querida guanabara gente aceito parabéns pa...</td>\n",
       "      <td>{'cantando', 'querida', 'dos', 'calcanhar', 'D...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2363</td>\n",
       "      <td>o bom xaxador</td>\n",
       "      <td>Jackson do Pandeiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jackson do Pandeiro - 1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>Depois do baião foi que veio o forró Depois do...</td>\n",
       "      <td>baião veio forró forró veio rojão pisada chão ...</td>\n",
       "      <td>{'pisada', 'Não', 'baião', 'Depois', 'xaxador'...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2364</td>\n",
       "      <td>cheguei agora</td>\n",
       "      <td>Jackson do Pandeiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jackson do Pandeiro - 1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>Beira mar beira do rio Ê ê beira mar Cheguei a...</td>\n",
       "      <td>beira mar beira rio ê ê beira mar cheguei beir...</td>\n",
       "      <td>{'Tem', 'candomblé', 'canta', 'nunca', 'Chegue...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                title               artist  \\\n",
       "0  2360         joão teimoso      Marília Batista   \n",
       "1  2361        morena sereia      Marília Batista   \n",
       "2  2362  parabéns, guanabara  Jackson do Pandeiro   \n",
       "3  2363        o bom xaxador  Jackson do Pandeiro   \n",
       "4  2364        cheguei agora  Jackson do Pandeiro   \n",
       "\n",
       "                                composer                       album  year  \\\n",
       "0           Noel Rosa / Marilia Batista.               Poeta da Vila  1953   \n",
       "1  José Maria De Abreu 1936 / Noel Rosa.               Poeta da Vila  1953   \n",
       "2                                    NaN  Jackson do Pandeiro - 1955  1955   \n",
       "3                                    NaN  Jackson do Pandeiro - 1955  1955   \n",
       "4                                    NaN  Jackson do Pandeiro - 1955  1955   \n",
       "\n",
       "                                               lyric  \\\n",
       "0  Tenho mais o que fazer Não discuto com teimoso...   \n",
       "1  Morena sereia Que à beira-mar não passeia Que ...   \n",
       "2  Rio, querida Guanabara Eu sou gente também Ace...   \n",
       "3  Depois do baião foi que veio o forró Depois do...   \n",
       "4  Beira mar beira do rio Ê ê beira mar Cheguei a...   \n",
       "\n",
       "                                         clean_lyric  \\\n",
       "0  discuto teimoso perder precioso viver joão tei...   \n",
       "1  morena sereia beiramar passeia senta praia dei...   \n",
       "2  rio querida guanabara gente aceito parabéns pa...   \n",
       "3  baião veio forró forró veio rojão pisada chão ...   \n",
       "4  beira mar beira rio ê ê beira mar cheguei beir...   \n",
       "\n",
       "                                        unique_words  decade  \n",
       "0  {'Este', 'Não', 'viver', 'fome', 'em', 'nome',...      50  \n",
       "1  {'dia', 'tu', 'esperança', 'Que', 'castelos', ...      50  \n",
       "2  {'cantando', 'querida', 'dos', 'calcanhar', 'D...      50  \n",
       "3  {'pisada', 'Não', 'baião', 'Depois', 'xaxador'...      50  \n",
       "4  {'Tem', 'candomblé', 'canta', 'nunca', 'Chegue...      50  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./clean_lyrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000032?line=0'>1</a>\u001b[0m \u001b[39m# gerando colunas de palavras únicas\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000032?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39munique_words\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mclean_lyric\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(generate_unique)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000032?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4322'>4323</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4323'>4324</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4329'>4330</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4330'>4331</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4331'>4332</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4430'>4431</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4431'>4432</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/series.py?line=4432'>4433</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/developer/emotion-mining-and-sentiment-analysis/.nlp/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb Cell 28'\u001b[0m in \u001b[0;36mgenerate_unique\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000034?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(text) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000034?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(text)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mateuslourenco/developer/emotion-mining-and-sentiment-analysis/preprocessing.ipynb#ch0000034?line=3'>4</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(text\u001b[39m.\u001b[39;49msplit())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# gerando colunas de palavras únicas\n",
    "df['unique_words'] = df['clean_lyric'].apply(generate_unique)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>composer</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>lyric</th>\n",
       "      <th>clean_lyric</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>3658</td>\n",
       "      <td>um casal de advogados</td>\n",
       "      <td>Trio Nordestino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trio Nordestino e Acompanhamento</td>\n",
       "      <td>1963</td>\n",
       "      <td>[ Eu conheci um casal de advogadosQue trabalha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{Fez, entrarE, profissãoE, apelarEntrou, cara,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>3663</td>\n",
       "      <td>dá, dá, dá nega</td>\n",
       "      <td>Trio Nordestino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trio Nordestino e Acompanhamento</td>\n",
       "      <td>1963</td>\n",
       "      <td>[ Quando ela ri faz um buraco na bochechaEu qu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{ta, ele, quero, me, fofinho, o, tão, dá, [, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>10902</td>\n",
       "      <td>deusa de itamaracá</td>\n",
       "      <td>Rasta Chinela</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rasta Chinela</td>\n",
       "      <td>2003</td>\n",
       "      <td>[ Sei que é para me matarTeu olhar, teu olharL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{vouPra, amor, vezes, possa, desejarDeusa, mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>10921</td>\n",
       "      <td>eu duvido</td>\n",
       "      <td>Rasta Chinela</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rasta Chinela</td>\n",
       "      <td>2003</td>\n",
       "      <td>[ Você pode revirar o mundoQue não vai achar n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{ninguém, Você, amorEu, cena, ta, terrorSinto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>12131</td>\n",
       "      <td>mão na urtiga</td>\n",
       "      <td>Zaíra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O Forró de Dona Zaíra</td>\n",
       "      <td>2008</td>\n",
       "      <td>(Instrumental - part. Hermeto Paschoal)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{-, (Instrumental, part., Paschoal), Hermeto}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  title           artist composer  \\\n",
       "1025   3658  um casal de advogados  Trio Nordestino      NaN   \n",
       "1029   3663        dá, dá, dá nega  Trio Nordestino      NaN   \n",
       "6271  10902     deusa de itamaracá    Rasta Chinela      NaN   \n",
       "6282  10921              eu duvido    Rasta Chinela      NaN   \n",
       "7123  12131          mão na urtiga            Zaíra      NaN   \n",
       "\n",
       "                                 album  year  \\\n",
       "1025  Trio Nordestino e Acompanhamento  1963   \n",
       "1029  Trio Nordestino e Acompanhamento  1963   \n",
       "6271                     Rasta Chinela  2003   \n",
       "6282                     Rasta Chinela  2003   \n",
       "7123             O Forró de Dona Zaíra  2008   \n",
       "\n",
       "                                                  lyric clean_lyric  \\\n",
       "1025  [ Eu conheci um casal de advogadosQue trabalha...         NaN   \n",
       "1029  [ Quando ela ri faz um buraco na bochechaEu qu...         NaN   \n",
       "6271  [ Sei que é para me matarTeu olhar, teu olharL...         NaN   \n",
       "6282  [ Você pode revirar o mundoQue não vai achar n...         NaN   \n",
       "7123            (Instrumental - part. Hermeto Paschoal)         NaN   \n",
       "\n",
       "                                           unique_words  \n",
       "1025  {Fez, entrarE, profissãoE, apelarEntrou, cara,...  \n",
       "1029  {ta, ele, quero, me, fofinho, o, tão, dá, [, b...  \n",
       "6271  {vouPra, amor, vezes, possa, desejarDeusa, mat...  \n",
       "6282  {ninguém, Você, amorEu, cena, ta, terrorSinto,...  \n",
       "7123      {-, (Instrumental, part., Paschoal), Hermeto}  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_lyric'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ Eu conheci um casal de advogadosQue trabalham separados na mesma profissãoE no processo que o doutor foi defenderA doutora foi fazer uma tremenda acusaçãoEla chegou e entrou na primeira varaFoi botando cara a cara a testemunha ocularE no final do processo ela perdeuE num instante recorreuE noutra vara foi entrarE dava pena ver o réu com aquela caraSai de vara entra em vara querendo absolvição E toda vez que o juiz absolviaNoutra vara ela ia querendo a condenaçãoUm certo dia ela acusou o moço Fez um grande alvoroço condenando o infelizE proibiu todo dia usar recurso De tentar mudar o curso de vara e de juizDisse ao doutor que ele quebraria a caraSe tentasse entrar na vara com a intenção de apelarEntrou na avara com o juizo ela estava E o processo segurava em toda vara do lugar ]'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1025, 'lyric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizando palavras\n",
    "df['clean_lyric'] = df['clean_lyric'].apply(normalize_text)\n",
    "df.to_csv('clean_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique(text):\n",
    "    if type(text) is not str:\n",
    "        print(text)\n",
    "    return set(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando lista de acordes para remoção dentro das letras\n",
    "chords_df = pd.read_csv('./chords.txt')\n",
    "chords_dicty = chords_df.to_dict()\n",
    "chords = set()\n",
    "\n",
    "for i in chords_dicty['chord']:\n",
    "    chords.add(chords_dicty['chord'][i].strip())\n",
    "    \n",
    "#função para remoção de acordes dentro de um texto\n",
    "def remove_chords(text):\n",
    "    txt_list = text.split()\n",
    "    return (' ').join(\n",
    "            word.strip()\n",
    "            for word in txt_list\n",
    "            if word.strip() not in chords\n",
    "        )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "def clean_lyrics(text):\n",
    "  txt = ''\n",
    "  #removendo acordes\n",
    "  txt = remove_chords(text)\n",
    "  #removendo tags de repetição 2x, 4x, etc\n",
    "  txt = txt.replace('[', '(').replace(']', ')')\n",
    "  txt = re.sub(r'\\([\\d]x\\)', '', txt)\n",
    "  #removendo palavras de orientação musical\n",
    "  txt = re.sub(r'\\((.*?)\\)', '', txt)  \n",
    "  #removendo pontuacao\n",
    "  txt = txt.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "  #caracteres em minusculo   \n",
    "  txt = txt.lower()\n",
    "  #remove stop words\n",
    "  doc = nlp(txt)\n",
    "  txt = ' '.join(token.text \n",
    "                  for token in doc \n",
    "                  if not token.is_stop\n",
    "                )\n",
    "    \n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enelvo.normaliser import Normaliser\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm = Normaliser(capitalize_pns=True)\n",
    "    return norm.normalise(text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQR2xgyW7WOrCQnX18yeFp",
   "collapsed_sections": [],
   "name": "higienizacao_df.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
